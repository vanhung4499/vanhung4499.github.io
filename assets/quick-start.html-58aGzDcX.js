import{_ as n,o as c,c as i,a as e}from"./app-CIGQMwlz.js";const h={};function a(o,t){return c(),i("div",null,t[0]||(t[0]=[e(`<h2 id="_1-huong-dan-nhanh-ve-elastic" tabindex="-1"><a class="header-anchor" href="#_1-huong-dan-nhanh-ve-elastic"><span>1. Hướng dẫn nhanh về Elastic</span></a></h2><blockquote><p>Giấy phép mã nguồn mở: <a href="https://github.com/elastic/elasticsearch/tree/7.4/licenses/APACHE-LICENSE-2.0.txt" target="_blank" rel="noopener noreferrer">Apache 2.0</a></p></blockquote><h2 id="_1-gioi-thieu" tabindex="-1"><a class="header-anchor" href="#_1-gioi-thieu"><span>1. Giới thiệu</span></a></h2><h3 id="_1-1-elastic-stack-la-gi" tabindex="-1"><a class="header-anchor" href="#_1-1-elastic-stack-la-gi"><span>1.1. Elastic Stack là gì</span></a></h3><p><strong>Elastic Stack</strong> còn được gọi là <strong>ELK Stack</strong>.</p><p>ELK là viết tắt của ba sản phẩm của công ty Elastic: <a href="https://www.elastic.co/cn/products/elasticsearch" target="_blank" rel="noopener noreferrer">ElasticSearch</a>, <a href="https://www.elastic.co/cn/products/logstash" target="_blank" rel="noopener noreferrer">Logstash</a>, và <a href="https://www.elastic.co/cn/products/kibana" target="_blank" rel="noopener noreferrer">Kibana</a>.</p><ul><li>Elasticsearch là một công cụ tìm kiếm và phân tích.</li><li>Logstash là một pipeline xử lý dữ liệu phía máy chủ, có khả năng thu thập dữ liệu từ nhiều nguồn cùng một lúc, chuyển đổi dữ liệu, sau đó gửi dữ liệu đến các &quot;kho lưu trữ&quot; như Elasticsearch.</li><li>Kibana cho phép người dùng trực quan hóa dữ liệu trong Elasticsearch bằng các biểu đồ và biểu đồ.</li></ul><p>Elastic Stack là phiên bản cập nhật của ELK Stack, sản phẩm mới nhất đã giới thiệu các bộ thu thập dữ liệu chức năng đơn lẻ nhẹ và đặt tên cho chúng là <a href="https://www.elastic.co/beats" target="_blank" rel="noopener noreferrer">Beats</a>.</p><h3 id="_1-2-tai-sao-su-dung-elastic-stack" tabindex="-1"><a class="header-anchor" href="#_1-2-tai-sao-su-dung-elastic-stack"><span>1.2. Tại sao sử dụng Elastic Stack</span></a></h3><p>Đối với các công ty có quy mô nhất định, thường sẽ có nhiều ứng dụng và được triển khai trên một số lượng lớn máy chủ. Nhân viên vận hành và phát triển thường cần xem nhật ký để xác định vấn đề. Nếu ứng dụng được triển khai theo cụm, hãy tưởng tượng nếu bạn đăng nhập vào từng máy chủ để xem nhật ký, điều này sẽ tốn nhiều thời gian và công sức.</p><p>Với giải pháp ELK, bạn có thể thu thập, tìm kiếm và phân tích nhật ký cùng một lúc.</p><h3 id="_1-3-kien-truc-elastic-stack" tabindex="-1"><a class="header-anchor" href="#_1-3-kien-truc-elastic-stack"><span>1.3. Kiến trúc Elastic Stack</span></a></h3><figure><img src="https://raw.githubusercontent.com/vanhung4499/images/master/snap/deploy3.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><blockquote><p><strong>Giải thích</strong></p><p>Đây là một sơ đồ kiến trúc của Elastic Stack. Từ hình trên, bạn có thể rõ ràng thấy hướng dòng dữ liệu.</p><ul><li><a href="https://www.elastic.co/products/beats" target="_blank" rel="noopener noreferrer">Beats</a> là một nền tảng truyền dữ liệu đơn chức năng, nó có thể gửi dữ liệu từ nhiều máy chủ đến Logstash hoặc ElasticSearch. Tuy nhiên, Beats không phải là một phần không thể thiếu, vì vậy bài viết này sẽ không giới thiệu.</li><li><a href="https://www.elastic.co/products/logstash" target="_blank" rel="noopener noreferrer">Logstash</a> là một pipeline thu thập dữ liệu động. Hỗ trợ thu thập dữ liệu theo nhiều cách như TCP/UDP/HTTP (cũng có thể nhận dữ liệu được Beats truyền đến), và xử lý dữ liệu để làm giàu hoặc trích xuất trường.</li><li><a href="https://www.elastic.co/products/elasticsearch" target="_blank" rel="noopener noreferrer">ElasticSearch</a> là một công cụ tìm kiếm và phân tích phân tán dựa trên JSON. Là trung tâm của ELK, nó lưu trữ dữ liệu tập trung.</li><li><a href="https://www.elastic.co/products/kibana" target="_blank" rel="noopener noreferrer">Kibana</a> là giao diện người dùng của ELK. Nó trực quan hóa dữ liệu đã thu thập (các báo cáo, dữ liệu hình học) và cung cấp giao diện để cấu hình, quản lý ELK.</li></ul></blockquote><h2 id="_2-elasticsearch" tabindex="-1"><a class="header-anchor" href="#_2-elasticsearch"><span>2. ElasticSearch</span></a></h2><blockquote><p><a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener noreferrer">Elasticsearch</a> là một công cụ tìm kiếm và phân tích dữ liệu phong cách RESTful, phân tán, có thể giải quyết nhiều trường hợp sử dụng xuất hiện liên tục. Là trung tâm của Elastic Stack, nó lưu trữ dữ liệu của bạn, giúp bạn khám phá các tình huống dự kiến và không dự kiến.</p></blockquote><h3 id="_2-1-gioi-thieu-ve-elasticsearch" tabindex="-1"><a class="header-anchor" href="#_2-1-gioi-thieu-ve-elasticsearch"><span>2.1. Giới thiệu về ElasticSearch</span></a></h3><p><a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener noreferrer">Elasticsearch</a> được phát triển dựa trên thư viện tìm kiếm <a href="https://github.com/apache/lucene-solr" target="_blank" rel="noopener noreferrer">Lucene</a>. Elasticsearch giấu đi sự phức tạp của Lucene, cung cấp giao diện API REST / Java dễ sử dụng (cũng như các giao diện API bằng ngôn ngữ khác).</p><p>Elasticsearch có thể được xem như một kho lưu trữ tài liệu, nơi nó <strong>chuyển đổi các cấu trúc dữ liệu phức tạp thành JSON để lưu trữ</strong>.</p><p><strong>ElasticSearch là một công cụ tìm kiếm toàn văn gần như thời gian thực</strong>, điều này có nghĩa là:</p><ul><li>Từ khi ghi dữ liệu đến khi dữ liệu có thể được tìm kiếm, có một độ trễ nhỏ (khoảng 1s)</li><li>Các hoạt động tìm kiếm và phân tích dựa trên ES có thể đạt được mức độ giây</li></ul><h4 id="_2-1-1-khai-niem-cot-loi" tabindex="-1"><a class="header-anchor" href="#_2-1-1-khai-niem-cot-loi"><span>2.1.1. Khái niệm cốt lõi</span></a></h4><ul><li><strong><code>Index</code></strong> có thể được coi là một tập hợp tối ưu của các tài liệu (document).</li><li>Mỗi <strong><code>document</code></strong> là một tập hợp các trường (field).</li><li><strong><code>Field</code></strong> là một cặp giá trị key-value chứa dữ liệu.</li><li>Theo mặc định, Elasticsearch xây dựng chỉ mục cho tất cả dữ liệu trong mỗi trường và mỗi trường chỉ mục đều có cấu trúc dữ liệu tối ưu hóa riêng.</li><li>Mỗi chỉ mục có thể có một hoặc nhiều loại (type). <code>Type</code> là một phân loại logic của chỉ mục,</li><li>Khi một máy không đủ để lưu trữ dữ liệu lớn, Elasticsearch có thể chia dữ liệu trong một chỉ mục thành nhiều <strong><code>shard</code></strong>. <strong><code>Shard</code></strong> được lưu trữ trên nhiều máy chủ. Với shard, bạn có thể mở rộng theo chiều ngang, lưu trữ nhiều dữ liệu hơn, cho phép các hoạt động tìm kiếm và phân tích được phân phối trên nhiều máy chủ, tăng cường throughput và hiệu suất. Mỗi shard đều là một chỉ mục lucene.</li><li>Bất kỳ máy chủ nào cũng có thể gặp sự cố hoặc bị tắt bất cứ lúc nào, lúc này shard có thể bị mất, do đó, bạn có thể tạo nhiều <strong><code>replica</code></strong> cho mỗi shard. Replica có thể cung cấp dịch vụ dự phòng khi shard gặp sự cố, đảm bảo dữ liệu không bị mất, nhiều replica cũng có thể tăng cường throughput và hiệu suất của hoạt động tìm kiếm. Primary shard (được thiết lập khi tạo chỉ mục, không thể sửa đổi, mặc định là 5), replica shard (có thể thay đổi số lượng bất cứ lúc nào, mặc định là 1), mặc định mỗi chỉ mục có 10 shard, 5 primary shard, 5 replica shard, cấu hình có sẵn tối thiểu, là 2 máy chủ.</li></ul><h3 id="_2-2-nguyen-ly-elasticsearch" tabindex="-1"><a class="header-anchor" href="#_2-2-nguyen-ly-elasticsearch"><span>2.2. Nguyên lý ElasticSearch</span></a></h3><h4 id="_2-2-1-qua-trinh-ghi-du-lieu-es" tabindex="-1"><a class="header-anchor" href="#_2-2-1-qua-trinh-ghi-du-lieu-es"><span>2.2.1. Quá trình ghi dữ liệu ES</span></a></h4><ul><li>Máy khách chọn một node và gửi yêu cầu đến, node này được gọi là <code>coordinating node</code> (nút điều phối).</li><li><code>Coordinating node</code> thực hiện <strong>định tuyến</strong> cho document và chuyển tiếp yêu cầu đến node tương ứng (có primary shard).</li><li><code>Primary shard</code> trên node thực tế xử lý yêu cầu, sau đó đồng bộ hóa dữ liệu với <code>replica node</code>.</li><li>Nếu <code>coordinating node</code> phát hiện <code>primary node</code> và tất cả <code>replica node</code> đều đã hoàn thành, nó sẽ trả lại kết quả phản hồi cho máy khách.</li></ul><h4 id="_2-2-2-qua-trinh-đoc-du-lieu-es" tabindex="-1"><a class="header-anchor" href="#_2-2-2-qua-trinh-đoc-du-lieu-es"><span>2.2.2. Quá trình đọc dữ liệu es</span></a></h4><p>Bạn có thể tìm kiếm theo <code>doc id</code>, sẽ dựa trên <code>doc id</code> để thực hiện hash, xác định xem lúc đó <code>doc id</code> đã được phân bổ vào shard nào, từ shard đó để tìm kiếm.</p><ul><li>Máy khách gửi yêu cầu đến <strong>bất kỳ</strong> một node, trở thành <code>coordinate node</code>.</li><li><code>Coordinate node</code> định tuyến <code>doc id</code> theo hash, chuyển yêu cầu đến node tương ứng, lúc này sẽ sử dụng thuật toán <strong>round-robin ngẫu nhiên</strong>, chọn ngẫu nhiên một trong số <code>primary shard</code> và tất cả các replica của nó, để cân bằng tải yêu cầu đọc.</li><li>Node nhận yêu cầu trả về document cho <code>coordinate node</code>.</li><li><code>Coordinate node</code> trả về document cho máy khách.</li></ul><h4 id="_2-2-3-nguyen-ly-co-ban-cua-viec-ghi-du-lieu" tabindex="-1"><a class="header-anchor" href="#_2-2-3-nguyen-ly-co-ban-cua-viec-ghi-du-lieu"><span>2.2.3. Nguyên lý cơ bản của việc ghi dữ liệu</span></a></h4><figure><img src="https://raw.githubusercontent.com/vanhung4499/images/master/snap/20240223111949.png" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><p>Đầu tiên, dữ liệu sẽ được ghi vào bộ đệm trong bộ nhớ (buffer), trong quá trình này dữ liệu không thể được tìm kiếm; đồng thời dữ liệu cũng được ghi vào tệp nhật ký translog.</p><p>Nếu bộ đệm gần như đầy, hoặc sau một khoảng thời gian nhất định, dữ liệu trong bộ đệm sẽ được <code>refresh</code> vào một <code>segment file</code> mới, nhưng lúc này dữ liệu không được ghi trực tiếp vào tệp <code>segment file</code> trên đĩa, mà phải đi vào <code>os cache</code> trước. Quá trình này được gọi là <code>refresh</code>.</p><p>Mỗi giây, ES sẽ ghi dữ liệu trong bộ đệm vào một <code>segment file</code> <strong>mới</strong>, mỗi giây sẽ tạo ra một tệp đĩa <code>segment file</code> <strong>mới</strong>, tệp <code>segment file</code> này sẽ lưu trữ dữ liệu được ghi vào bộ đệm trong 1 giây gần đây.</p><p>Tuy nhiên, nếu không có dữ liệu trong bộ đệm, thì tất nhiên không có quá trình refresh nào được thực hiện, nếu có dữ liệu trong bộ đệm, mặc định sẽ thực hiện một lần refresh mỗi giây, đẩy dữ liệu vào một <code>segment file</code> mới.</p><p>Trên hệ điều hành, tệp đĩa thực tế đều có một thứ gọi là <code>os cache</code>, tức là trước khi dữ liệu được ghi vào tệp đĩa, nó sẽ được đưa vào <code>os cache</code> trước, đầu tiên vào bộ nhớ cache cấp hệ điều hành. Chỉ cần dữ liệu trong bộ đệm được chuyển vào <code>os cache</code> thông qua hoạt động refresh, dữ liệu này có thể được tìm kiếm.</p><p>Tại sao nói rằng ES là <strong>gần như thời gian thực</strong>? <code>NRT</code>, tên đầy đủ là <code>near real-time</code>. Mặc định là refresh mỗi giây một lần, vì vậy ES là gần như thời gian thực, vì dữ liệu được ghi vào sau 1 giây mới có thể được tìm thấy. Bạn có thể sử dụng <code>restful api</code> của es hoặc <code>java api</code> để thực hiện một hoạt động refresh <strong>thủ công</strong>, tức là thủ công đưa dữ liệu trong bộ đệm vào <code>os cache</code>, để dữ liệu có thể được tìm kiếm ngay lập tức. Miễn là dữ liệu được đưa vào <code>os cache</code>, bộ đệm sẽ được làm sạch, vì không cần giữ bộ đệm nữa, dữ liệu đã được lưu trữ trong tệp nhật ký translog một lần.</p><p>Lặp lại các bước trên, dữ liệu mới liên tục vào bộ đệm và translog, liên tục ghi dữ liệu <code>buffer</code> vào một <code>segment file</code> mới sau mỗi lần <code>refresh</code>, sau mỗi lần <code>refresh</code> bộ đệm sẽ được làm sạch, translog sẽ được giữ lại. Khi quá trình này tiếp diễn, translog sẽ ngày càng lớn. Khi translog đạt đến một độ dài nhất định, nó sẽ kích hoạt hoạt động <code>commit</code>.</p><p>Bước đầu tiên của hoạt động commit là ghi dữ liệu hiện có trong bộ đệm vào <code>os cache</code>, sau đó làm sạch bộ đệm. Sau đó, ghi một <code>commit point</code> vào tệp đĩa, trong đó đánh dấu tất cả các <code>segment file</code> tương ứng với <code>commit point</code> này, đồng thời buộc <code>os cache</code> chứa tất cả dữ liệu hiện tại để được <code>fsync</code> vào tệp đĩa. Cuối cùng, <strong>xóa</strong> tệp nhật ký translog hiện tại, khởi động lại một translog, lúc này hoạt động commit đã hoàn thành.</p><p>Hoạt động commit này được gọi là <code>flush</code>. Mặc định là mỗi 30 phút tự động thực hiện một lần <code>flush</code>, nhưng nếu translog quá lớn, cũng sẽ kích hoạt <code>flush</code>. Hoạt động flush tương ứng với toàn bộ quá trình commit, chúng ta có thể thông qua api của es, thực hiện thủ công hoạt động flush, thủ công <code>fsync</code> dữ liệu trong <code>os cache</code> vào đĩa.</p><p>Tệp nhật ký translog có vai trò gì? Trước khi bạn thực hiện hoạt động commit, dữ liệu có thể đang nằm trong bộ đệm hoặc nằm trong <code>os cache</code>. Dù là bộ đệm hay <code>os cache</code> đều là bộ nhớ, nếu máy này bị hỏng, dữ liệu trong bộ nhớ sẽ mất hết. Vì vậy, cần ghi các hoạt động tương ứng của dữ liệu vào một tệp nhật ký đặc biệt là <code>translog</code>, nếu máy bị hỏng lúc này, khi khởi động lại, es sẽ tự động đọc dữ liệu từ tệp nhật ký translog và phục hồi vào bộ nhớ <code>buffer</code> và <code>os cache</code>.</p><p>Thực tế, translog cũng được ghi vào <code>os cache</code> trước, mặc định là mỗi 5 giây sẽ đẩy vào đĩa một lần, vì vậy mặc định, có thể có 5 giây dữ liệu chỉ nằm trong bộ đệm hoặc <code>os cache</code> hoặc tệp translog, không nằm trên đĩa, nếu máy này bị hỏng lúc này, sẽ <strong>mất</strong> 5 giây dữ liệu. Nhưng hiệu suất như vậy tốt hơn, mất tối đa 5 giây dữ liệu. Bạn cũng có thể đặt translog để mỗi lần ghi phải <code>fsync</code> trực tiếp vào đĩa, nhưng hiệu suất sẽ kém hơn nhiều.</p><p>Thực tế, nếu bạn ở đây, nếu người phỏng vấn không hỏi bạn về vấn đề mất dữ liệu của es, bạn có thể tự hào với người phỏng vấn ở đây, bạn nói, thực tế es trước tiên là gần như thời gian thực, dữ liệu được ghi vào sau 1 giây mới có thể được tìm thấy; có thể mất dữ liệu. Có 5 giây dữ liệu, nằm trong bộ đệm, <code>os cache</code> của translog, <code>os cache</code> của <code>segment file</code>, không nằm trên đĩa, nếu máy này bị hỏng lúc này, sẽ dẫn đến <strong>mất</strong> 5 giây dữ liệu.</p><p><strong>Tóm lại</strong>, dữ liệu được ghi vào bộ đệm trước, sau đó mỗi giây, dữ liệu sẽ được refresh vào <code>os cache</code>, khi dữ liệu đến <code>os cache</code>, dữ liệu có thể được tìm kiếm (đó là lý do tại sao chúng ta nói rằng từ khi dữ liệu được ghi vào cho đến khi có thể tìm kiếm, có độ trễ 1s). Mỗi 5 giây, dữ liệu sẽ được ghi vào tệp translog (do đó, nếu máy bị hỏng, tất cả dữ liệu trong bộ nhớ sẽ mất, tối đa sẽ mất 5s dữ liệu), khi translog lớn đến một mức độ nhất định, hoặc mặc định mỗi 30 phút, một hoạt động commit sẽ được kích hoạt, đẩy tất cả dữ liệu trong bộ đệm vào tệp <code>segment file</code>trên đĩa.</p><blockquote><p>Sau khi dữ liệu được ghi vào <code>segment file</code>, chỉ mục đảo ngược cũng sẽ được tạo ngay lập tức.</p></blockquote><h4 id="_2-2-4-nguyen-ly-co-ban-khi-xoa-cap-nhat-du-lieu" tabindex="-1"><a class="header-anchor" href="#_2-2-4-nguyen-ly-co-ban-khi-xoa-cap-nhat-du-lieu"><span>2.2.4. Nguyên lý cơ bản khi xóa/cập nhật dữ liệu</span></a></h4><p>Nếu là hoạt động xóa, khi commit sẽ tạo ra một tệp <code>.del</code>, trong đó đánh dấu một doc nhất định là trạng thái <code>deleted</code>, vì vậy khi tìm kiếm, dựa vào tệp <code>.del</code>, bạn sẽ biết liệu doc có bị xóa hay không.</p><p>Nếu là hoạt động cập nhật, nó sẽ đánh dấu doc gốc là trạng thái <code>deleted</code> và sau đó ghi một dữ liệu mới.</p><p>Mỗi khi bộ đệm được refresh, một <code>segment file</code> sẽ được tạo ra, vì vậy mặc định là một <code>segment file</code> mỗi giây, vì vậy <code>segment file</code> sẽ ngày càng nhiều, lúc này sẽ thường xuyên thực hiện merge. Mỗi lần merge, nhiều <code>segment file</code> sẽ được hợp nhất thành một, đồng thời ở đây, doc được đánh dấu là <code>deleted</code> sẽ được <strong>xóa vật lý</strong>, sau đó ghi <code>segment file</code> mới vào đĩa, ở đây sẽ ghi một <code>commit point</code>, đánh dấu tất cả <code>segment file</code> mới, sau đó mở <code>segment file</code> để tìm kiếm, và sau đó xóa <code>segment file</code> cũ.</p><h4 id="_2-2-5-lop-co-ban-lucene" tabindex="-1"><a class="header-anchor" href="#_2-2-5-lop-co-ban-lucene"><span>2.2.5. Lớp cơ bản Lucene</span></a></h4><p>Đơn giản, Lucene chỉ là một thư viện jar, bên trong nó chứa các mã thuật toán đã được đóng gói để tạo chỉ mục đảo ngược. Khi chúng ta phát triển bằng Java, chúng ta chỉ cần import thư viện jar Lucene, sau đó phát triển dựa trên API của Lucene.</p><p>Thông qua Lucene, chúng ta có thể tạo chỉ mục cho dữ liệu hiện có, Lucene sẽ tổ chức cấu trúc dữ liệu chỉ mục trên ổ đĩa cục bộ cho chúng ta.</p><h4 id="_2-2-5-chi-muc-đao-nguoc" tabindex="-1"><a class="header-anchor" href="#_2-2-5-chi-muc-đao-nguoc"><span>2.2.5. Chỉ mục đảo ngược</span></a></h4><p>Trong công cụ tìm kiếm, mỗi tài liệu đều có một ID tài liệu tương ứng, nội dung tài liệu được biểu diễn dưới dạng một tập hợp các từ khóa. Ví dụ, sau khi phân loại, tài liệu 1 đã trích xuất 20 từ khóa, mỗi từ khóa đều ghi lại số lần xuất hiện và vị trí xuất hiện của nó trong tài liệu.</p><p>Vậy, chỉ mục đảo ngược là ánh xạ từ <strong>từ khóa đến ID tài liệu</strong>, mỗi từ khóa đều tương ứng với một loạt tài liệu, trong đó tất cả các tài liệu đều xuất hiện từ khóa.</p><p>Ví dụ.</p><p>Có các tài liệu sau:</p><table><thead><tr><th>DocId</th><th>Doc</th></tr></thead><tbody><tr><td>1</td><td>Cha của Google Maps chuyển sang Facebook</td></tr><tr><td>2</td><td>Cha của Google Maps gia nhập Facebook</td></tr><tr><td>3</td><td>Người sáng lập Google Maps, Lars rời Google để gia nhập Facebook</td></tr><tr><td>4</td><td>Cha của Google Maps chuyển sang Facebook có liên quan đến việc hủy dự án Wave</td></tr><tr><td>5</td><td>Cha của Google Maps, Lars gia nhập trang web xã hội Facebook</td></tr></tbody></table><p>Sau khi phân loại tài liệu, chúng ta nhận được chỉ mục <strong>đảo ngược</strong> sau.</p><table><thead><tr><th>WordId</th><th>Word</th><th>DocIds</th></tr></thead><tbody><tr><td>1</td><td>Google</td><td>1,2,3,4,5</td></tr><tr><td>2</td><td>Maps</td><td>1,2,3,4,5</td></tr><tr><td>3</td><td>Cha</td><td>1,2,4,5</td></tr><tr><td>4</td><td>Chuyển sang</td><td>1,4</td></tr><tr><td>5</td><td>Facebook</td><td>1,2,3,4,5</td></tr><tr><td>6</td><td>Gia nhập</td><td>2,3,5</td></tr><tr><td>7</td><td>Người sáng lập</td><td>3</td></tr><tr><td>8</td><td>Lars</td><td>3,5</td></tr><tr><td>9</td><td>Rời</td><td>3</td></tr><tr><td>10</td><td>Và</td><td>4</td></tr><tr><td>..</td><td>..</td><td>..</td></tr></tbody></table><p>Ngoài ra, chỉ mục đảo ngược hữu ích còn có thể ghi lại nhiều thông tin hơn, chẳng hạn như thông tin tần suất tài liệu, cho biết có bao nhiêu tài liệu chứa một từ nhất định trong tập hợp tài liệu.</p><p>Vì vậy, với chỉ mục đảo ngược, công cụ tìm kiếm có thể dễ dàng phản hồi truy vấn của người dùng. Ví dụ, người dùng nhập truy vấn <code>Facebook</code>, hệ thống tìm kiếm tra cứu chỉ mục đảo ngược, đọc từ đó các tài liệu chứa từ này, các tài liệu này là kết quả tìm kiếm được cung cấp cho người dùng.</p><p>Cần chú ý đến hai chi tiết quan trọng của chỉ mục đảo ngược:</p><ul><li>Tất cả các mục từ trong chỉ mục đảo ngược tương ứng với một hoặc nhiều tài liệu;</li><li>Các mục từ trong chỉ mục đảo ngược được sắp xếp theo thứ tự từ điển tăng dần.</li></ul><blockquote><p>Trên chỉ là một ví dụ đơn giản, không được sắp xếp theo thứ tự từ điển tăng dần một cách nghiêm ngặt.</p></blockquote><h2 id="_3-logstash" tabindex="-1"><a class="header-anchor" href="#_3-logstash"><span>3. Logstash</span></a></h2><blockquote><p><a href="https://github.com/elastic/logstash" target="_blank" rel="noopener noreferrer">Logstash</a> là một pipeline xử lý dữ liệu phía máy chủ mã nguồn mở, có khả năng thu thập dữ liệu từ nhiều nguồn cùng một lúc, chuyển đổi dữ liệu, sau đó gửi dữ liệu đến &quot;kho lưu trữ&quot; mà bạn thích.</p></blockquote><h3 id="_3-1-gioi-thieu-ve-logstash" tabindex="-1"><a class="header-anchor" href="#_3-1-gioi-thieu-ve-logstash"><span>3.1. Giới thiệu về Logstash</span></a></h3><p>Logstash có thể truyền và xử lý nhật ký, giao dịch hoặc dữ liệu khác của bạn.</p><p>Logstash là pipeline dữ liệu tốt nhất của Elasticsearch.</p><p>Logstash sử dụng mô hình quản lý dạng plugin, có thể sử dụng plugin để tùy chỉnh trong quá trình nhập, lọc, xuất cũng như mã hóa. Cộng đồng Logstash có hơn 200 plugin có sẵn.</p><h3 id="_3-2-nguyen-ly-hoat-đong-cua-logstash" tabindex="-1"><a class="header-anchor" href="#_3-2-nguyen-ly-hoat-đong-cua-logstash"><span>3.2. Nguyên lý hoạt động của Logstash</span></a></h3><p>Logstash có hai yếu tố cần thiết: <code>input</code> và <code>output</code>, và một yếu tố tùy chọn: <code>filter</code>.</p><p>Ba yếu tố này, tương ứng với ba giai đoạn xử lý sự kiện của Logstash: nhập &gt; bộ lọc &gt; xuất.</p><figure><img src="https://raw.githubusercontent.com/vanhung4499/images/master/snap/basic_logstash_pipeline.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><ul><li><code>input</code> - chịu trách nhiệm thu thập dữ liệu từ nguồn dữ liệu.</li><li><strong><code>filter</code></strong> - chỉnh sửa dữ liệu theo định dạng hoặc nội dung bạn chỉ định.</li><li><strong><code>output</code></strong> - chuyển dữ liệu đến điểm đến.</li></ul><p>Trong các tình huống ứng dụng thực tế, thường có nhiều hơn một đầu vào, đầu ra, bộ lọc. Logstash sử dụng cách quản lý dạng plugin cho ba yếu tố này, người dùng có thể lựa chọn linh hoạt các plugin cần thiết ở mỗi giai đoạn và kết hợp chúng để sử dụng.</p><h2 id="_4-beats" tabindex="-1"><a class="header-anchor" href="#_4-beats"><span>4. Beats</span></a></h2><blockquote><p><strong><a href="https://github.com/elastic/beats" target="_blank" rel="noopener noreferrer">Beats</a> là đại lý chuyển tiếp dữ liệu được cài đặt trên máy chủ</strong>.</p><p>Beats có thể truyền dữ liệu trực tiếp đến Elasticsearch hoặc truyền đến Logstash.</p></blockquote><figure><img src="https://raw.githubusercontent.com/vanhung4499/images/master/snap/beats-platform.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>Beats có nhiều loại, bạn có thể chọn loại phù hợp dựa trên nhu cầu ứng dụng thực tế.</p><p>Các loại phổ biến bao gồm:</p><ul><li><strong>Packetbeat:</strong> Phân tích gói dữ liệu mạng, cung cấp thông tin về các giao dịch trao đổi giữa các máy chủ ứng dụng của bạn.</li><li><strong>Filebeat:</strong> Gửi tệp nhật ký từ máy chủ của bạn.</li><li><strong>Metricbeat:</strong> Là một đại lý giám sát máy chủ, thu thập chỉ số từ hệ điều hành và dịch vụ chạy trên máy chủ định kỳ.</li><li><strong>Winlogbeat:</strong> Cung cấp nhật ký sự kiện Windows.</li></ul><h3 id="_4-1-gioi-thieu-ve-filebeat" tabindex="-1"><a class="header-anchor" href="#_4-1-gioi-thieu-ve-filebeat"><span>4.1. Giới thiệu về Filebeat</span></a></h3><blockquote><p><em>Vì tôi chỉ tiếp xúc với Filebeat, nên bài viết này chỉ giới thiệu về Filebeat trong các thành phần của Beats</em>.</p></blockquote><p>So với Logstash, FileBeat nhẹ nhàng hơn.</p><p>Trong bất kỳ môi trường nào, ứng dụng đều có khả năng ngừng hoạt động. Filebeat đọc và chuyển tiếp các dòng nhật ký, nếu bị gián đoạn, nó sẽ ghi nhớ vị trí của tất cả các sự kiện khi trạng thái trực tuyến được khôi phục.</p><p>Filebeat đi kèm với các mô-đun nội bộ (auditd, Apache, Nginx, System và MySQL), có thể đơn giản hóa việc thu thập, phân tích và trực quan hóa định dạng nhật ký thông thường thông qua một lệnh chỉ định.</p><p>FileBeat sẽ không làm cho pipeline của bạn quá tải. Nếu FileBeat truyền dữ liệu đến Logstash, khi Logstash bận xử lý dữ liệu, nó sẽ thông báo cho FileBeat làm chậm tốc độ đọc. Một khi tắc nghẽn được giải quyết, FileBeat sẽ trở lại tốc độ ban đầu và tiếp tục truyền.</p><figure><img src="https://raw.githubusercontent.com/vanhung4499/images/master/snap/filebeat.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="_4-2-nguyen-ly-hoat-đong-cua-filebeat" tabindex="-1"><a class="header-anchor" href="#_4-2-nguyen-ly-hoat-đong-cua-filebeat"><span>4.2. Nguyên lý hoạt động của Filebeat</span></a></h3><p>Filebeat có hai thành phần chính:</p><ul><li><code>harvester</code>: chịu trách nhiệm đọc nội dung của một tệp. Nó sẽ đọc từng dòng nội dung của tệp và gửi nội dung đến điểm đến xuất.</li><li><code>prospector</code>: chịu trách nhiệm quản lý harvester và tìm tất cả các nguồn tệp cần đọc. Ví dụ, nếu loại là nhật ký, prospector sẽ duyệt qua tất cả các tệp phù hợp với yêu cầu trong đường dẫn đã chỉ định.</li></ul><div class="language-yaml" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#abb2bf;--shiki-dark:#abb2bf;--shiki-light-bg:#282c34;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#E06C75;--shiki-dark:#E06C75;">filebeat.prospectors</span><span style="--shiki-light:#ABB2BF;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#ABB2BF;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#E06C75;--shiki-dark:#E06C75;">type</span><span style="--shiki-light:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#98C379;--shiki-dark:#98C379;">log</span></span>
<span class="line"><span style="--shiki-light:#E06C75;--shiki-dark:#E06C75;">    paths</span><span style="--shiki-light:#ABB2BF;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#ABB2BF;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#98C379;--shiki-dark:#98C379;">/var/log/*.log</span></span>
<span class="line"><span style="--shiki-light:#ABB2BF;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#98C379;--shiki-dark:#98C379;">/var/path2/*.log</span></span></code></pre></div><p>Filebeat duy trì trạng thái của mỗi tệp và thường xuyên làm mới trạng thái đĩa trong tệp đăng ký. Trạng thái được sử dụng để ghi nhớ vị trí độ lệch cuối cùng mà harvester đang đọc và đảm bảo tất cả các dòng nhật ký được gửi.</p><p>Filebeat lưu trạng thái gửi của mỗi sự kiện trong tệp đăng ký. Vì vậy, nó có thể đảm bảo rằng sự kiện được gửi ít nhất một lần đến xuất được cấu hình, không có dữ liệu bị mất.</p><h2 id="_5-van-hanh" tabindex="-1"><a class="header-anchor" href="#_5-van-hanh"><span>5. Vận hành</span></a></h2><ul><li>[[Elasticsearch Operations|Vận hành ElasticSearch]]</li><li>[[Logstash Operation|Vận hành Logstash]]</li><li>[[Kibana Operation|Vận hành Kibana]]</li><li>[[Filebeat Operation]]</li></ul><h2 id="_6-tai-lieu-tham-khao" tabindex="-1"><a class="header-anchor" href="#_6-tai-lieu-tham-khao"><span>6. Tài liệu tham khảo</span></a></h2><ul><li><strong>Nguồn chính thức</strong><ul><li><a href="https://www.elastic.co/products/elasticsearch" target="_blank" rel="noopener noreferrer">Trang chủ Elasticsearch</a></li><li><a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener noreferrer">Elasticsearch Github</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html" target="_blank" rel="noopener noreferrer">Tài liệu chính thức Elasticsearch</a></li><li><a href="https://www.elastic.co/products/logstash" target="_blank" rel="noopener noreferrer">Trang chủ Logstash</a></li><li><a href="https://github.com/elastic/logstash" target="_blank" rel="noopener noreferrer">Logstash Github</a></li><li><a href="https://www.elastic.co/guide/en/logstash/current/index.html" target="_blank" rel="noopener noreferrer">Tài liệu chính thức Logstash</a></li><li><a href="https://www.elastic.co/products/kibana" target="_blank" rel="noopener noreferrer">Trang chủ Kibana</a></li><li><a href="https://github.com/elastic/kibana" target="_blank" rel="noopener noreferrer">Kibana Github</a></li><li><a href="https://www.elastic.co/guide/en/kibana/current/index.html" target="_blank" rel="noopener noreferrer">Tài liệu chính thức Kibana</a></li><li><a href="https://www.elastic.co/products/beats" target="_blank" rel="noopener noreferrer">Trang chủ Beats</a></li><li><a href="https://github.com/elastic/beats" target="_blank" rel="noopener noreferrer">Beats Github</a></li><li><a href="https://www.elastic.co/guide/en/beats/libbeat/current/index.html" target="_blank" rel="noopener noreferrer">Tài liệu chính thức Beats</a></li></ul></li><li><strong>Bài viết</strong><ul><li><a href="https://www.elastic.co/what-is/elk-stack" target="_blank" rel="noopener noreferrer">ELK Stack là gì?</a></li><li><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/es-introduction.md" target="_blank" rel="noopener noreferrer">https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/es-introduction.md</a></li><li><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/es-write-query-search.md" target="_blank" rel="noopener noreferrer">es-write-query-search</a></li></ul></li></ul>`,100)]))}const s=n(h,[["render",a],["__file","quick-start.html.vue"]]),r=JSON.parse('{"path":"/database/elastic/quick-start.html","title":"Elastic Quick Start","lang":"en-US","frontmatter":{"title":"Elastic Quick Start","icon":"cib:elastic-stack","tags":["elastic","logstash","kibana"],"categories":["elastic"],"order":2,"description":"1. Hướng dẫn nhanh về Elastic Giấy phép mã nguồn mở: Apache 2.0 1. Giới thiệu 1.1. Elastic Stack là gì Elastic Stack còn được gọi là ELK Stack. ELK là viết tắt của ba sản phẩm c...","head":[["meta",{"property":"og:url","content":"https://vanhung4499.github.io/database/elastic/quick-start.html"}],["meta",{"property":"og:site_name","content":"VanHung4499"}],["meta",{"property":"og:title","content":"Elastic Quick Start"}],["meta",{"property":"og:description","content":"1. Hướng dẫn nhanh về Elastic Giấy phép mã nguồn mở: Apache 2.0 1. Giới thiệu 1.1. Elastic Stack là gì Elastic Stack còn được gọi là ELK Stack. ELK là viết tắt của ba sản phẩm c..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/vanhung4499/images/master/snap/deploy3.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-06-28T15:54:38.000Z"}],["meta",{"property":"article:author","content":"Hung Nguyen"}],["meta",{"property":"article:tag","content":"elastic"}],["meta",{"property":"article:tag","content":"logstash"}],["meta",{"property":"article:tag","content":"kibana"}],["meta",{"property":"article:modified_time","content":"2024-06-28T15:54:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Elastic Quick Start\\",\\"image\\":[\\"https://raw.githubusercontent.com/vanhung4499/images/master/snap/deploy3.png\\",\\"https://raw.githubusercontent.com/vanhung4499/images/master/snap/20240223111949.png\\",\\"https://raw.githubusercontent.com/vanhung4499/images/master/snap/basic_logstash_pipeline.png\\",\\"https://raw.githubusercontent.com/vanhung4499/images/master/snap/beats-platform.png\\",\\"https://raw.githubusercontent.com/vanhung4499/images/master/snap/filebeat.png\\"],\\"dateModified\\":\\"2024-06-28T15:54:38.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Hung Nguyen\\",\\"url\\":\\"https://vanhung4499.github.io\\"}]}"]]},"headers":[{"level":2,"title":"1. Hướng dẫn nhanh về Elastic","slug":"_1-huong-dan-nhanh-ve-elastic","link":"#_1-huong-dan-nhanh-ve-elastic","children":[]},{"level":2,"title":"1. Giới thiệu","slug":"_1-gioi-thieu","link":"#_1-gioi-thieu","children":[{"level":3,"title":"1.1. Elastic Stack là gì","slug":"_1-1-elastic-stack-la-gi","link":"#_1-1-elastic-stack-la-gi","children":[]},{"level":3,"title":"1.2. Tại sao sử dụng Elastic Stack","slug":"_1-2-tai-sao-su-dung-elastic-stack","link":"#_1-2-tai-sao-su-dung-elastic-stack","children":[]},{"level":3,"title":"1.3. Kiến trúc Elastic Stack","slug":"_1-3-kien-truc-elastic-stack","link":"#_1-3-kien-truc-elastic-stack","children":[]}]},{"level":2,"title":"2. ElasticSearch","slug":"_2-elasticsearch","link":"#_2-elasticsearch","children":[{"level":3,"title":"2.1. Giới thiệu về ElasticSearch","slug":"_2-1-gioi-thieu-ve-elasticsearch","link":"#_2-1-gioi-thieu-ve-elasticsearch","children":[]},{"level":3,"title":"2.2. Nguyên lý ElasticSearch","slug":"_2-2-nguyen-ly-elasticsearch","link":"#_2-2-nguyen-ly-elasticsearch","children":[]}]},{"level":2,"title":"3. Logstash","slug":"_3-logstash","link":"#_3-logstash","children":[{"level":3,"title":"3.1. Giới thiệu về Logstash","slug":"_3-1-gioi-thieu-ve-logstash","link":"#_3-1-gioi-thieu-ve-logstash","children":[]},{"level":3,"title":"3.2. Nguyên lý hoạt động của Logstash","slug":"_3-2-nguyen-ly-hoat-đong-cua-logstash","link":"#_3-2-nguyen-ly-hoat-đong-cua-logstash","children":[]}]},{"level":2,"title":"4. Beats","slug":"_4-beats","link":"#_4-beats","children":[{"level":3,"title":"4.1. Giới thiệu về Filebeat","slug":"_4-1-gioi-thieu-ve-filebeat","link":"#_4-1-gioi-thieu-ve-filebeat","children":[]},{"level":3,"title":"4.2. Nguyên lý hoạt động của Filebeat","slug":"_4-2-nguyen-ly-hoat-đong-cua-filebeat","link":"#_4-2-nguyen-ly-hoat-đong-cua-filebeat","children":[]}]},{"level":2,"title":"5. Vận hành","slug":"_5-van-hanh","link":"#_5-van-hanh","children":[]},{"level":2,"title":"6. Tài liệu tham khảo","slug":"_6-tai-lieu-tham-khao","link":"#_6-tai-lieu-tham-khao","children":[]}],"git":{"createdTime":1719590078000,"updatedTime":1719590078000,"contributors":[{"name":"Hung Nguyen Van","email":"vanhung4499@gmail.com","commits":1}]},"readingTime":{"minutes":17.61,"words":5283},"filePathRelative":"database/elastic/quick-start.md","localizedDate":"June 28, 2024","excerpt":"<h2>1. Hướng dẫn nhanh về Elastic</h2>\\n<blockquote>\\n<p>Giấy phép mã nguồn mở: <a href=\\"https://github.com/elastic/elasticsearch/tree/7.4/licenses/APACHE-LICENSE-2.0.txt\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Apache 2.0</a></p>\\n</blockquote>\\n<h2>1. Giới thiệu</h2>\\n<h3>1.1. Elastic Stack là gì</h3>","autoDesc":true}');export{s as comp,r as data};
