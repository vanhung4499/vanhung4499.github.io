import{_ as n,g as r,o as s,c as o,e,h as a,f as i,w as p,a as t}from"./app-BRTHG7K9.js";const c={},d=t('<h1 id="【模型接入】llama" tabindex="-1"><a class="header-anchor" href="#【模型接入】llama"><span>【模型接入】LLAMA</span></a></h1><p>项目基于 Spring AI 提供的 <a href="https://github.com/spring-projects/spring-ai/tree/main/models/spring-ai-ollama" target="_blank" rel="noopener noreferrer"><code>spring-ai-ollama</code></a>，实现 Llama 的接入：</p><table><thead><tr><th>功能</th><th>模型</th><th>Spring AI 客户端</th></tr></thead><tbody><tr><td>AI 对话</td><td>llama3、llama2</td><td><a href="https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html" target="_blank" rel="noopener noreferrer">Ollama Chat</a></td></tr><tr><td>AI 绘画</td><td><a href="https://new.qq.com/rain/a/20240420A005CK00" target="_blank" rel="noopener noreferrer">llama3 支持生成图片</a></td><td>暂未支持</td></tr></tbody></table><h2 id="_1-申请密钥-私有部署" tabindex="-1"><a class="header-anchor" href="#_1-申请密钥-私有部署"><span><a href="#_1-%E7%94%B3%E8%AF%B7%E5%AF%86%E9%92%A5-%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2">#</a> 1. 申请密钥（私有部署）</span></a></h2><p>Llama 是 Meta 开源的模型，所以可以私有化部署。</p><h3 id="_1-1-私有化部署" tabindex="-1"><a class="header-anchor" href="#_1-1-私有化部署"><span><a href="#_1-1-%E7%A7%81%E6%9C%89%E5%8C%96%E9%83%A8%E7%BD%B2">#</a> 1.1 私有化部署</span></a></h3><p>① 访问 <a href="https://ollama.ai/download" target="_blank" rel="noopener noreferrer">Ollama 官网</a>，下载对应系统 Ollama 客户端，然后安装。</p><p>② 安装完成后，在命令中执行 <code>ollama run llama3</code> 命令，一键部署 <code>llama3</code> 模型。</p><hr><p>部署完成后，可以在我们系统的 [AI 大模型 -&gt; 控制台 -&gt; API 密钥] 菜单，进行密钥的配置。需要填写“密钥” + “自定义 API URL”（因为让 Spring AI 使用该地址）。如下图所示：</p><figure><img src="https://doc.iocoder.cn/img/AI手册/模型接入/LLAMA-私有.png" alt="私有的密钥配置" tabindex="0" loading="lazy"><figcaption>私有的密钥配置</figcaption></figure><h3 id="_1-2-补充说明" tabindex="-1"><a class="header-anchor" href="#_1-2-补充说明"><span><a href="#_1-2-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E">#</a> 1.2 补充说明</span></a></h3>',12),h=e("code",null,"llama3",-1),m=e("code",null,"max_tokens",-1),g=t(`<h2 id="_2-如何使用" tabindex="-1"><a class="header-anchor" href="#_2-如何使用"><span><a href="#_2-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8">#</a> 2. 如何使用？</span></a></h2><p>① 如果你的项目里需要直接通过 <code>@Resource</code> 注入 OllamaChatModel 等对象，需要把 <code>application.yaml</code> 配置文件里的 <code>spring.ai.ollama</code> 配置项，替换成你的！</p><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>spring:</span></span>
<span class="line"><span>  ai:</span></span>
<span class="line"><span>    ollama:</span></span>
<span class="line"><span>      base-url: http://127.0.0.1:11434 # 你的私有化部署地址</span></span>
<span class="line"><span>      chat:</span></span>
<span class="line"><span>        model: llama3</span></span></code></pre></div><p>② 如果你希望使用 [AI 大模型 -&gt; 控制台 -&gt; API 密钥] 菜单的密钥配置，则可以通过 AiApiKeyService 的 <code>#getChatModel(...)</code> 方法，获取对应的模型对象。</p><hr><p>① 和 ② 这两者的后续使用，就是标准的 Spring AI 客户端的使用，调用对应的方法即可。</p><p>另外，LlamaChatModelTests 里有对应的测试用例，可以参考。</p>`,7);function _(f,A){const l=r("RouteLink");return s(),o("div",null,[d,e("p",null,[a("如果后续你要体验 "),i(l,{to:"/ai/chat/"},{default:p(()=>[a("《AI 对话》")]),_:1}),a(" ，需要在 [AI 大模型 -> 控制台 -> 聊天模型] 菜单，配置对应的聊天模型为 "),h,a("，然后它的 "),m,a("（回复数 Token 数）填写 4096 即可。")]),g])}const b=n(c,[["render",_],["__file","llama.html.vue"]]),k=JSON.parse('{"path":"/project/rouyi-vue-pro/ai/llama.html","title":"【模型接入】LLAMA","lang":"en-US","frontmatter":{"title":"【模型接入】LLAMA","tags":["project","java","spring-boot","spring-cloud"],"categories":["project"],"order":137,"feed":false,"seo":false,"head":[]},"headers":[{"level":2,"title":"# 1. 申请密钥（私有部署）","slug":"_1-申请密钥-私有部署","link":"#_1-申请密钥-私有部署","children":[{"level":3,"title":"# 1.1 私有化部署","slug":"_1-1-私有化部署","link":"#_1-1-私有化部署","children":[]},{"level":3,"title":"# 1.2 补充说明","slug":"_1-2-补充说明","link":"#_1-2-补充说明","children":[]}]},{"level":2,"title":"# 2. 如何使用？","slug":"_2-如何使用","link":"#_2-如何使用","children":[]}],"git":{"createdTime":1720365235000,"updatedTime":1720365235000,"contributors":[{"name":"Hung Nguyen Van","email":"vanhung4499@gmail.com","commits":1}]},"readingTime":{"minutes":1.63,"words":490},"filePathRelative":"project/rouyi-vue-pro/ai/llama.md","localizedDate":"July 7, 2024"}');export{b as comp,k as data};
